---
lastUpdated: true
editLink: true
footer: true
outline: deep
---


# 大模型相关知识学习记录


## 大模型理论基础
### 大模型基础组件 Tokenizer

Tokenizer 分词器是 NLP 大模型最基础的组件，基于 Tokenizer 可以将文本转换成独立的 token 列表，进而转换成输入的向量成为计算机可以理解的输入形式。<sup>[[1](#ref-nghuyong_Tokenizer)]</sup>


## 大模型开发框架
### transformers


## 参考资料


- <span id="ref-nghuyong_Tokenizer">[1]</span> [大模型基础组件 - Tokenizer - nghuyong的文章 - 知乎](https://zhuanlan.zhihu.com/p/651430181)
